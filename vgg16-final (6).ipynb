{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"t_train='../input/kfoldfinal/k-fold-cross-final-ds/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v_validation='../input/kfoldfinal/k-fold-cross-final-ds/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras.utils\nfrom keras.models import Input,Model\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D , Dense, ZeroPadding2D, Activation\nfrom keras import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras import utils as np_utils\nfrom keras.initializers import glorot_uniform\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.multiclass import unique_labels\nfrom matplotlib import pyplot as plt\nfrom pprint import pprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=sorted(os.listdir(t_train))\nprint('There are {} having names:\\n{}'.format(len(classes),classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\\ reading all the images from the folders\nimages_list=dict()\nfor i in classes:\n    images_list[i]=sorted(os.listdir(os.path.join(t_train, i)))\n    print('{0} \\t--> {1}'.format(len(images_list[i]),i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=sorted(os.listdir(v_validation))\nprint('There are {} having names:\\n{}'.format(len(classes),classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\\ reading all the images from the folders\nimages_list=dict()\nfor i in classes:\n    images_list[i]=sorted(os.listdir(os.path.join(v_validation, i)))\n    print('{0} \\t--> {1}'.format(len(images_list[i]),i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CATEGORIES = ['COVID19','Normal','Pneumonia']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for category in CATEGORIES:  # do dogs and cats\n    path = os.path.join(t_train,category)  \n    for img in os.listdir(path): \n        img_array = cv2.imread(os.path.join(path,img))  # convert to array\n        \n        plt.imshow(img_array)\n        plt.show()  # display!\n\n        break  # we just want one for now so break\n    break  #...and one more!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**validation set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for category in CATEGORIES:  \n    path = os.path.join(v_validation,category) \n    for img in os.listdir(path):  \n        img_array = cv2.imread(os.path.join(path,img))  # convert to array\n        plt.imshow(img_array)\n        plt.show()\n        \n        plt.imshow(img_array)  # graph it\n        plt.show()  # display!\n        \n        break  # we just want one for now so break\n    break  #...and one more!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE=224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:  \n\n        path = os.path.join(t_train,category)  \n        class_num = CATEGORIES.index(category) \n        print('this is class num',class_num)\n#         print(len(class_num[0]))\n        for img in os.listdir(path):  \n            try:\n                hist_equalization_trainset = cv2.imread(os.path.join(path,img))  # convert to array\n                new_array = cv2.resize(hist_equalization_trainset, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n                training_data.append([new_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_list=dict()\nfor i in classes:\n    images_list[i]=os.listdir(os.path.join(t_train, i))\n    print('{0} \\t--> {1}'.format(len(images_list[i]),i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(training_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" random.shuffle(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sample in training_data[:10]:\n    print(sample[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny = np.array(y)\nX=X/255.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cata=len(CATEGORIES)\nprint(cata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = keras.utils.to_categorical(y, cata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\tgen = ImageDataGenerator(\n\t\trotation_range=20,\n\t\tzoom_range=0.15,\n\t\twidth_shift_range=0.2,\n\t\theight_shift_range=0.2,\n\t\tshear_range=0.15,\n\t\thorizontal_flip=True,\n\t\tfill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data = []\n\ndef create_validation_data():\n    for category in CATEGORIES: \n\n        path = os.path.join(v_validation,category)  \n        class_num = CATEGORIES.index(category) \n        print('this is class num',class_num)\n\n        for img in os.listdir(path): \n            try:\n                hist_equalization_validationset = cv2.imread(os.path.join(path,img))  # convert to array\n                new_array = cv2.resize(hist_equalization_validationset, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n                validation_data.append([new_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_validation_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(validation_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(validation_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in validation_data[:10]:\n    print(item[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x = []\nval_y = []\n\nfor f,l in validation_data:\n    val_x.append(f)\n    val_y.append(l)\n\nval_x = np.array(val_x).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\nval_y = np.array(val_y)\nval_x=val_x/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_y = keras.utils.to_categorical(val_y, cata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for l in val_y:\n    print(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 15\nepochs = 50\nsteps_per_epoch=len(X) // batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16_model=keras.applications.vgg16.VGG16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(vgg16_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to make the model sequential\nmodel = Sequential()\nfor layer in vgg16_model.layers:\n    model.add(layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove the last dense layer\nmodel = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n  layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.add(Dense(128,activation='softmax'))\nmodel.add(Dense(3,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint(\"/kaggle/working/best_model.h5\", monitor='accuracy', verbose=1,save_best_only=True, mode='auto', period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(gen.flow(X, y, batch_size=batch_size),epochs=epochs,verbose=2,steps_per_epoch=steps_per_epoch,callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/best_model.h5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_eval =model.evaluate(val_x, val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test loss:', test_eval[0])\nprint('Test accuracy:', test_eval[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predictions\npreds = model.predict(val_x)\npreds = np.argmax(preds, axis=1)\n\n# Original labels\norig_test_labels = np.argmax(val_y, axis=1)\nprint(orig_test_labels.shape)\nprint(preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\nprint(precision_score(orig_test_labels, preds,average='macro'))\nprint(recall_score(orig_test_labels, preds,average='macro'))\nprint(f1_score(orig_test_labels, preds,average='macro'))\nprint(accuracy_score(orig_test_labels, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\ncm = metrics.confusion_matrix(orig_test_labels, preds)\nprint(cm)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nplt.xticks(range(3), ['COVID','Normal', 'Pneumonia'], fontsize=10)\nplt.yticks(range(3), ['COVID','Normal', 'Pneumonia'], fontsize=10)\nall_sample_title = 'Accuracy Score: {0}'.format( test_eval[1])\nplt.title(all_sample_title, size = 15);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_image=plt.imread('../input/testing/testing/cp.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=plt.imshow(my_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.transform import resize\nmy_img_resized=resize(my_image,(224,224,3))\nimg=plt.imshow(my_img_resized)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nprobabilities=model.predict(np.array([my_img_resized,]))\nprobabilities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_to_class=['COVID19','Normal','Pneumonia']\nindex=np.argsort(probabilities[0,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Most likely class:\",number_to_class[index[2]],\"..Probability:\",probabilities[0,index[2]])\nprint(\"Second most likely class:\",number_to_class[index[1]],\"..Probability:\",probabilities[0,index[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}